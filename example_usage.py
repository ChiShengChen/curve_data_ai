#!/usr/bin/env python3
"""
ğŸš€ Curveæ­·å²æ•¸æ“šæ‰¹é‡ç²å–ç³»çµ± - å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ“´å±•å¾Œçš„æ‰¹é‡ç²å–åŠŸèƒ½
"""

import os
import pandas as pd
from datetime import datetime
from free_historical_data import FreeHistoricalDataCollector, AVAILABLE_POOLS, get_high_priority_pools, get_stable_pools

def example_1_quick_start():
    """ğŸ å¿«é€Ÿé–‹å§‹ - ç²å–3poolçš„æ­·å²æ•¸æ“š"""
    
    print("=" * 60)
    print("ğŸ ç¤ºä¾‹1: å¿«é€Ÿé–‹å§‹")
    print("=" * 60)
    
    collector = FreeHistoricalDataCollector()
    
    # ç²å–3poolçš„7å¤©æ•¸æ“š
    print("ğŸ“Š ç²å–3poolçš„7å¤©æ­·å²æ•¸æ“š...")
    data = collector.get_comprehensive_free_data(
        pool_name='3pool',
        days=7
    )
    
    if not data.empty:
        print(f"âœ… æˆåŠŸç²å– {len(data)} æ¢æ•¸æ“š")
        print(f"ğŸ“… æ•¸æ“šæ™‚é–“ç¯„åœ: {data['timestamp'].min()} åˆ° {data['timestamp'].max()}")
        print(f"ğŸ’° Virtual Priceç¯„åœ: {data['virtual_price'].min():.6f} - {data['virtual_price'].max():.6f}")
        
        # ä¿å­˜æ•¸æ“š
        data.to_csv('example_3pool_7d.csv', index=False)
        print("ğŸ’¾ æ•¸æ“šå·²ä¿å­˜åˆ°: example_3pool_7d.csv")
    else:
        print("âŒ æœªç²å–åˆ°æ•¸æ“š")

def example_2_batch_by_type():
    """ğŸŠ æŒ‰é¡å‹æ‰¹é‡ç²å–"""
    
    print("\n" + "=" * 60)
    print("ğŸŠ ç¤ºä¾‹2: æŒ‰æ± å­é¡å‹æ‰¹é‡ç²å–")
    print("=" * 60)
    
    collector = FreeHistoricalDataCollector()
    
    # ç²å–æ‰€æœ‰ç©©å®šå¹£æ± çš„æ•¸æ“š
    stable_pools = get_stable_pools()
    print(f"ğŸ“‹ æ‰¾åˆ° {len(stable_pools)} å€‹ç©©å®šå¹£æ± ")
    
    batch_data = collector.get_batch_historical_data(
        pools_dict=stable_pools,
        days=3,  # ç²å–3å¤©æ•¸æ“šç”¨æ–¼å¿«é€Ÿæ¸¬è©¦
        max_concurrent=2,  # ä¸¦ç™¼æ•¸
        delay_between_requests=1  # è«‹æ±‚é–“å»¶é²
    )
    
    print(f"âœ… æ‰¹é‡ç²å–å®Œæˆï¼Œå…± {len(batch_data)} å€‹æ± å­")
    
    # é¡¯ç¤ºå„æ± å­æ•¸æ“šçµ±è¨ˆ
    for pool_name, data in batch_data.items():
        if not data.empty:
            print(f"  ğŸ“Š {pool_name:12}: {len(data)} æ¢æ•¸æ“š, VPç¯„åœ {data['virtual_price'].min():.6f}-{data['virtual_price'].max():.6f}")
        else:
            print(f"  âŒ {pool_name:12}: ç„¡æ•¸æ“š")

def example_3_comprehensive_analysis():
    """ğŸ“ˆ ç¶œåˆåˆ†æ - é«˜å„ªå…ˆç´šæ± å­å°æ¯”"""
    
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ç¤ºä¾‹3: é«˜å„ªå…ˆç´šæ± å­ç¶œåˆåˆ†æ")
    print("=" * 60)
    
    collector = FreeHistoricalDataCollector()
    
    # ç²å–é«˜å„ªå…ˆç´šæ± å­
    high_priority_pools = get_high_priority_pools()
    print(f"ğŸ† é«˜å„ªå…ˆç´šæ± å­: {list(high_priority_pools.keys())}")
    
    # æ‰¹é‡ç²å–7å¤©æ•¸æ“š
    batch_data = collector.get_batch_historical_data(
        pools_dict=high_priority_pools,
        days=7,
        max_concurrent=3
    )
    
    # åˆ†ææ•¸æ“š
    analysis_results = {}
    
    for pool_name, data in batch_data.items():
        if not data.empty and len(data) > 1:
            # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
            vp_start = data['virtual_price'].iloc[0]
            vp_end = data['virtual_price'].iloc[-1] 
            total_return = (vp_end / vp_start - 1) * 100
            volatility = data['virtual_price'].pct_change().std() * 100
            
            analysis_results[pool_name] = {
                'total_return_pct': total_return,
                'volatility_pct': volatility,
                'data_points': len(data),
                'avg_virtual_price': data['virtual_price'].mean()
            }
    
    # é¡¯ç¤ºåˆ†æçµæœ
    print("\nğŸ“Š 7å¤©è¡¨ç¾åˆ†æ:")
    print(f"{'æ± å­':<12} {'ç¸½æ”¶ç›Šç‡(%)':<12} {'æ³¢å‹•ç‡(%)':<10} {'æ•¸æ“šé»':<8} {'å¹³å‡VP':<12}")
    print("-" * 65)
    
    for pool_name, stats in analysis_results.items():
        print(f"{pool_name:<12} {stats['total_return_pct']:>+10.4f}  {stats['volatility_pct']:>8.4f}  {stats['data_points']:>6d}  {stats['avg_virtual_price']:>10.6f}")

def example_4_custom_selection():
    """ğŸ¯ è‡ªå®šç¾©é¸æ“‡ - æŒ‡å®šæ± å­ç²å–"""
    
    print("\n" + "=" * 60)
    print("ğŸ¯ ç¤ºä¾‹4: è‡ªå®šç¾©æ± å­é¸æ“‡")
    print("=" * 60)
    
    collector = FreeHistoricalDataCollector()
    
    # è‡ªå®šç¾©æ± å­é¸æ“‡
    custom_pools = {
        '3pool': AVAILABLE_POOLS['3pool'],
        'frax': AVAILABLE_POOLS['frax'], 
        'lusd': AVAILABLE_POOLS['lusd']
    }
    
    print(f"ğŸ“‹ è‡ªå®šç¾©é¸æ“‡çš„æ± å­: {list(custom_pools.keys())}")
    
    # ç²å–5å¤©æ•¸æ“š
    batch_data = collector.get_batch_historical_data(
        pools_dict=custom_pools,
        days=5,
        max_concurrent=2
    )
    
    # è¨ˆç®—ç›¸é—œæ€§åˆ†æ
    print("\nğŸ”— æ± å­é–“Virtual Priceç›¸é—œæ€§åˆ†æ:")
    
    # æ§‹å»ºåƒ¹æ ¼DataFrame
    price_data = pd.DataFrame()
    for pool_name, data in batch_data.items():
        if not data.empty:
            # ä½¿ç”¨timestampä½œç‚ºç´¢å¼•å°é½Šæ•¸æ“š
            temp_df = data.set_index('timestamp')['virtual_price']
            price_data[pool_name] = temp_df
    
    if not price_data.empty:
        # è¨ˆç®—ç›¸é—œæ€§çŸ©é™£
        correlation_matrix = price_data.corr()
        
        # é¡¯ç¤ºç›¸é—œæ€§
        print(correlation_matrix.round(4))
        
        # æ‰¾å‡ºæœ€é«˜ç›¸é—œæ€§
        max_corr = 0
        max_pair = None
        for i in correlation_matrix.index:
            for j in correlation_matrix.columns:
                if i != j:
                    corr_val = correlation_matrix.loc[i, j]
                    if abs(corr_val) > abs(max_corr):
                        max_corr = corr_val
                        max_pair = (i, j)
        
        if max_pair:
            print(f"\nğŸ”— æœ€é«˜ç›¸é—œæ€§: {max_pair[0]} èˆ‡ {max_pair[1]} ({max_corr:.4f})")

def example_5_data_processing():
    """ğŸ”„ æ•¸æ“šè™•ç† - æ¸…ç†å’Œè½‰æ›"""
    
    print("\n" + "=" * 60)
    print("ğŸ”„ ç¤ºä¾‹5: æ•¸æ“šè™•ç†å’Œè½‰æ›")
    print("=" * 60)
    
    collector = FreeHistoricalDataCollector()
    
    # ç²å–3poolæ•¸æ“š
    data = collector.get_comprehensive_free_data('3pool', days=10)
    
    if data.empty:
        print("âŒ ç„¡æ³•ç²å–æ•¸æ“š")
        return
    
    print(f"ğŸ“Š åŸå§‹æ•¸æ“š: {len(data)} æ¢è¨˜éŒ„")
    
    # æ•¸æ“šæ¸…ç†å’Œè™•ç†
    processed_data = data.copy()
    
    # 1. æ·»åŠ æŠ€è¡“æŒ‡æ¨™
    processed_data['vp_change_pct'] = processed_data['virtual_price'].pct_change() * 100
    processed_data['vp_ma_5'] = processed_data['virtual_price'].rolling(5).mean()
    processed_data['vp_std_5'] = processed_data['virtual_price'].rolling(5).std()
    
    # 2. æ·»åŠ æ™‚é–“ç‰¹å¾µ
    processed_data['hour'] = pd.to_datetime(processed_data['timestamp']).dt.hour
    processed_data['day_of_week'] = pd.to_datetime(processed_data['timestamp']).dt.dayofweek
    
    # 3. åˆªé™¤ç¼ºå¤±å€¼
    processed_data = processed_data.dropna()
    
    print(f"âœ… è™•ç†å¾Œæ•¸æ“š: {len(processed_data)} æ¢è¨˜éŒ„")
    
    # æ•¸æ“šçµ±è¨ˆ
    print("\nğŸ“ˆ Virtual Priceçµ±è¨ˆ:")
    vp_stats = processed_data['virtual_price'].describe()
    for stat_name, stat_value in vp_stats.items():
        print(f"  {stat_name:8}: {stat_value:.8f}")
    
    # åƒ¹æ ¼è®ŠåŒ–çµ±è¨ˆ
    print("\nğŸ“Š åƒ¹æ ¼è®ŠåŒ–çµ±è¨ˆ:")
    change_stats = processed_data['vp_change_pct'].describe()
    for stat_name, stat_value in change_stats.items():
        print(f"  {stat_name:8}: {stat_value:+.6f}%")
    
    # ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š
    processed_data.to_csv('example_processed_3pool.csv', index=False)
    print("\nğŸ’¾ è™•ç†å¾Œçš„æ•¸æ“šå·²ä¿å­˜åˆ°: example_processed_3pool.csv")

def example_6_production_ready():
    """ğŸ­ ç”Ÿç”¢å°±ç·’ - å®Œæ•´çš„æ•¸æ“šç®¡é“"""
    
    print("\n" + "=" * 60)
    print("ğŸ­ ç¤ºä¾‹6: ç”Ÿç”¢ç´šæ•¸æ“šç®¡é“")
    print("=" * 60)
    
    collector = FreeHistoricalDataCollector()
    
    # ç”Ÿç”¢ç´šé…ç½®
    production_pools = get_high_priority_pools()  # åªè™•ç†é«˜å„ªå…ˆç´šæ± å­
    days_to_collect = 30  # ç²å–30å¤©æ•¸æ“š
    
    print(f"ğŸ­ ç”Ÿç”¢é…ç½®:")
    print(f"  ğŸ“‹ æ± å­æ•¸é‡: {len(production_pools)}")
    print(f"  ğŸ“… æ•¸æ“šå¤©æ•¸: {days_to_collect}")
    print(f"  ğŸ• é–‹å§‹æ™‚é–“: {datetime.now()}")
    
    try:
        # æ‰¹é‡ç²å–æ•¸æ“š
        print("\nğŸš€ é–‹å§‹æ‰¹é‡æ•¸æ“šç²å–...")
        batch_data = collector.get_batch_historical_data(
            pools_dict=production_pools,
            days=days_to_collect,
            max_concurrent=2,  # ç”Ÿç”¢ç’°å¢ƒä½¿ç”¨è¼ƒä½ä¸¦ç™¼é¿å…è¢«é™åˆ¶
            delay_between_requests=2  # å¢åŠ å»¶é²é¿å…è§¸ç™¼é™åˆ¶
        )
        
        # æ•¸æ“šè³ªé‡æª¢æŸ¥
        print("\nğŸ” æ•¸æ“šè³ªé‡æª¢æŸ¥:")
        quality_report = {}
        
        for pool_name, data in batch_data.items():
            if not data.empty:
                # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
                expected_points = days_to_collect * 4  # æ¯å¤©4å€‹é»
                actual_points = len(data)
                completeness = (actual_points / expected_points) * 100
                
                # æª¢æŸ¥æ•¸æ“šç•°å¸¸å€¼
                vp_q1 = data['virtual_price'].quantile(0.25)
                vp_q3 = data['virtual_price'].quantile(0.75)
                vp_iqr = vp_q3 - vp_q1
                outliers = len(data[(data['virtual_price'] < vp_q1 - 1.5*vp_iqr) | 
                                  (data['virtual_price'] > vp_q3 + 1.5*vp_iqr)])
                
                quality_report[pool_name] = {
                    'completeness_pct': completeness,
                    'outliers_count': outliers,
                    'data_points': actual_points
                }
                
                print(f"  ğŸ“Š {pool_name:12}: å®Œæ•´åº¦ {completeness:5.1f}%, ç•°å¸¸å€¼ {outliers:2d}å€‹, æ•¸æ“šé» {actual_points:3d}")
        
        # ç”Ÿæˆç”Ÿç”¢å ±å‘Š
        report_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"production_report_{report_time}.txt"
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ­ Curveæ•¸æ“šç²å–ç”Ÿç”¢å ±å‘Š\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now()}\n")
            f.write(f"æ± å­æ•¸é‡: {len(production_pools)}\n") 
            f.write(f"æ•¸æ“šå¤©æ•¸: {days_to_collect}\n\n")
            
            f.write("æ•¸æ“šè³ªé‡å ±å‘Š:\n")
            f.write("-" * 30 + "\n")
            for pool_name, quality in quality_report.items():
                f.write(f"{pool_name:12}: å®Œæ•´åº¦ {quality['completeness_pct']:5.1f}%, "
                       f"ç•°å¸¸å€¼ {quality['outliers_count']:2d}å€‹, "
                       f"æ•¸æ“šé» {quality['data_points']:3d}\n")
        
        print(f"\nğŸ“‹ ç”Ÿç”¢å ±å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
        
        # å°å‡ºæ‰¹é‡æ•¸æ“šç‚ºExcel
        try:
            with pd.ExcelWriter(f'production_data_{report_time}.xlsx') as writer:
                for pool_name, data in batch_data.items():
                    if not data.empty:
                        data.to_excel(writer, sheet_name=pool_name, index=False)
            
            print(f"ğŸ“Š æ‰¹é‡æ•¸æ“šå·²å°å‡ºç‚ºExcel: production_data_{report_time}.xlsx")
        except Exception as e:
            print(f"âš ï¸  Excelå°å‡ºå¤±æ•—: {e}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿç”¢ç®¡é“åŸ·è¡Œå¤±æ•—: {e}")

def main():
    """ğŸ¯ ä¸»å‡½æ•¸ - åŸ·è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    
    print("ğŸš€ Curveæ‰¹é‡æ­·å²æ•¸æ“šç²å– - å®Œæ•´ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 80)
    
    # æª¢æŸ¥ç·©å­˜ç›®éŒ„
    cache_dir = "free_historical_cache"
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
        print(f"ğŸ“ å‰µå»ºç·©å­˜ç›®éŒ„: {cache_dir}")
    
    try:
        # åŸ·è¡Œæ‰€æœ‰ç¤ºä¾‹
        example_1_quick_start()
        example_2_batch_by_type() 
        example_3_comprehensive_analysis()
        example_4_custom_selection()
        example_5_data_processing()
        example_6_production_ready()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹åŸ·è¡Œå®Œæˆï¼")
        print("=" * 80)
        
        # é¡¯ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
        for filename in os.listdir('.'):
            if filename.startswith('example_') or filename.startswith('production_'):
                file_size = os.path.getsize(filename) / 1024  # KB
                print(f"  ğŸ“„ {filename} ({file_size:.1f}KB)")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 