#!/usr/bin/env python3
"""
Curveæ•°æ®ç®¡ç†æ¨¡å—
æ”¯æŒCSVå­˜å‚¨ã€è¯»å–ã€æ¸…ç†å’Œåˆ†æ
"""

import os
import pandas as pd
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union
from pathlib import Path

from real_data_collector import CurveRealDataCollector, CurvePoolData
from config import Config

class CurveDataManager:
    """Curveæ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, data_dir: str = "curve_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.data_dir / "real_time").mkdir(exist_ok=True)
        (self.data_dir / "historical").mkdir(exist_ok=True)
        (self.data_dir / "backups").mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
        web3_url = Config.get_web3_provider_url()
        self.collector = CurveRealDataCollector(web3_url)
        
        print(f"ğŸ“ æ•°æ®ç›®å½•: {self.data_dir.absolute()}")
    
    def save_real_time_data(self, pool_name: str, save_csv: bool = True) -> Optional[str]:
        """è·å–å¹¶ä¿å­˜å®æ—¶æ•°æ®"""
        
        print(f"ğŸ“Š è·å– {pool_name} å®æ—¶æ•°æ®...")
        
        try:
            # è·å–å®æ—¶æ•°æ®
            pool_data = self.collector.get_real_time_data(pool_name)
            
            if not pool_data:
                print(f"âŒ æ— æ³•è·å– {pool_name} æ•°æ®")
                return None
            
            # è½¬æ¢ä¸ºDataFrame
            df = self._pool_data_to_df(pool_data)
            
            if save_csv:
                # ä¿å­˜ä¸ºCSV
                timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{pool_name}_realtime_{timestamp_str}.csv"
                filepath = self.data_dir / "real_time" / filename
                
                df.to_csv(filepath, index=False, encoding='utf-8')
                print(f"âœ… å®æ—¶æ•°æ®å·²ä¿å­˜: {filepath}")
                
                # åŒæ—¶ä¿å­˜æœ€æ–°æ•°æ® (è¦†ç›–)
                latest_file = self.data_dir / "real_time" / f"{pool_name}_latest.csv"
                df.to_csv(latest_file, index=False, encoding='utf-8')
                
                return str(filepath)
            else:
                print(f"ğŸ“Š æ•°æ®è·å–æˆåŠŸä½†æœªä¿å­˜ (save_csv=False)")
                return None
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å®æ—¶æ•°æ®å¤±è´¥: {e}")
            return None
    
    def save_historical_data(self, pool_name: str, days: int = 30, save_csv: bool = True) -> Optional[str]:
        """è·å–å¹¶ä¿å­˜å†å²æ•°æ®"""
        
        print(f"ğŸ“ˆ è·å– {pool_name} å†å²æ•°æ® ({days}å¤©)...")
        
        try:
            # è·å–å†å²æ•°æ®
            df = self.collector.get_historical_data(pool_name, days)
            
            if df.empty:
                print(f"âŒ æ— æ³•è·å– {pool_name} å†å²æ•°æ®")
                return None
            
            if save_csv:
                # ä¿å­˜ä¸ºCSV
                timestamp_str = datetime.now().strftime("%Y%m%d")
                filename = f"{pool_name}_historical_{days}d_{timestamp_str}.csv"
                filepath = self.data_dir / "historical" / filename
                
                df.to_csv(filepath, index=False, encoding='utf-8')
                print(f"âœ… å†å²æ•°æ®å·²ä¿å­˜: {filepath} ({len(df)} æ¡è®°å½•)")
                
                return str(filepath)
            else:
                print(f"ğŸ“ˆ å†å²æ•°æ®è·å–æˆåŠŸä½†æœªä¿å­˜ (save_csv=False)")
                return None
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å†å²æ•°æ®å¤±è´¥: {e}")
            return None
    
    def save_all_pools_data(self, pools: Optional[List[str]] = None, save_csv: bool = True) -> Dict[str, str]:
        """æ‰¹é‡ä¿å­˜å¤šä¸ªæ± å­çš„æ•°æ®"""
        
        if pools is None:
            pools = list(Config.CURVE_POOLS.keys())
        
        results = {}
        
        print(f"ğŸ”„ æ‰¹é‡è·å– {len(pools)} ä¸ªæ± å­çš„æ•°æ®...")
        
        for pool_name in pools:
            print(f"\n--- å¤„ç† {pool_name} ---")
            
            # å®æ—¶æ•°æ®
            realtime_file = self.save_real_time_data(pool_name, save_csv)
            if realtime_file:
                results[f"{pool_name}_realtime"] = realtime_file
            
            # å†å²æ•°æ® (7å¤©)
            historical_file = self.save_historical_data(pool_name, days=7, save_csv=save_csv)
            if historical_file:
                results[f"{pool_name}_historical"] = historical_file
        
        # ä¿å­˜æ‰¹é‡æ“ä½œè®°å½•
        if save_csv and results:
            batch_record = {
                'timestamp': datetime.now().isoformat(),
                'pools_processed': pools,
                'files_created': results,
                'total_files': len(results)
            }
            
            record_file = self.data_dir / f"batch_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(batch_record, f, indent=2, ensure_ascii=False)
            
            print(f"\nğŸ“‹ æ‰¹é‡æ“ä½œè®°å½•å·²ä¿å­˜: {record_file}")
        
        return results
    
    def load_csv_data(self, filepath: str) -> pd.DataFrame:
        """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®"""
        
        try:
            df = pd.read_csv(filepath)
            
            # å°è¯•è§£ææ—¶é—´æˆ³åˆ—
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            print(f"âœ… å·²åŠ è½½æ•°æ®: {filepath} ({len(df)} æ¡è®°å½•)")
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½CSVå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_latest_data(self, pool_name: str) -> Optional[pd.DataFrame]:
        """è·å–æŒ‡å®šæ± å­çš„æœ€æ–°æ•°æ®"""
        
        latest_file = self.data_dir / "real_time" / f"{pool_name}_latest.csv"
        
        if latest_file.exists():
            return self.load_csv_data(str(latest_file))
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ° {pool_name} çš„æœ€æ–°æ•°æ®ï¼Œå°è¯•è·å–...")
            self.save_real_time_data(pool_name)
            
            if latest_file.exists():
                return self.load_csv_data(str(latest_file))
        
        return None
    
    def list_saved_files(self) -> Dict[str, List[str]]:
        """åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„æ–‡ä»¶"""
        
        files = {
            'real_time': [],
            'historical': [],
            'backups': []
        }
        
        for category in files.keys():
            dir_path = self.data_dir / category
            if dir_path.exists():
                csv_files = list(dir_path.glob("*.csv"))
                files[category] = [f.name for f in csv_files]
        
        return files
    
    def cleanup_old_files(self, days_to_keep: int = 7):
        """æ¸…ç†æ—§æ–‡ä»¶"""
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        deleted_count = 0
        
        for dir_name in ['real_time', 'historical', 'backups']:
            dir_path = self.data_dir / dir_name
            
            if dir_path.exists():
                for file_path in dir_path.glob("*.csv"):
                    # è·³è¿‡ latest æ–‡ä»¶
                    if 'latest' in file_path.name:
                        continue
                    
                    # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                    
                    if file_time < cutoff_date:
                        file_path.unlink()
                        deleted_count += 1
        
        print(f"ğŸ—‘ï¸  å·²æ¸…ç† {deleted_count} ä¸ªè¶…è¿‡ {days_to_keep} å¤©çš„æ—§æ–‡ä»¶")
    
    def create_summary_report(self) -> str:
        """åˆ›å»ºæ•°æ®æ±‡æ€»æŠ¥å‘Š"""
        
        files = self.list_saved_files()
        
        report = ["ğŸ“Š Curveæ•°æ®å­˜å‚¨æ±‡æ€»æŠ¥å‘Š", "=" * 40]
        report.append(f"æ•°æ®ç›®å½•: {self.data_dir.absolute()}")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ–‡ä»¶ç»Ÿè®¡
        total_files = sum(len(file_list) for file_list in files.values())
        report.append(f"ğŸ“ æ–‡ä»¶ç»Ÿè®¡:")
        report.append(f"  - å®æ—¶æ•°æ®: {len(files['real_time'])} ä¸ªæ–‡ä»¶")
        report.append(f"  - å†å²æ•°æ®: {len(files['historical'])} ä¸ªæ–‡ä»¶")  
        report.append(f"  - å¤‡ä»½æ–‡ä»¶: {len(files['backups'])} ä¸ªæ–‡ä»¶")
        report.append(f"  - æ€»è®¡: {total_files} ä¸ªæ–‡ä»¶")
        report.append("")
        
        # æœ€æ–°æ•°æ®çŠ¶æ€
        report.append("ğŸ”„ æœ€æ–°æ•°æ®çŠ¶æ€:")
        for pool_name in Config.CURVE_POOLS.keys():
            latest_file = self.data_dir / "real_time" / f"{pool_name}_latest.csv"
            if latest_file.exists():
                file_time = datetime.fromtimestamp(latest_file.stat().st_mtime)
                age = datetime.now() - file_time
                status = "ğŸŸ¢ æ–°" if age.total_seconds() < 3600 else "ğŸŸ¡ æ—§" if age.total_seconds() < 86400 else "ğŸ”´ è¿‡æœŸ"
                report.append(f"  - {pool_name}: {status} ({age})")
            else:
                report.append(f"  - {pool_name}: âŒ æ— æ•°æ®")
        
        report_text = "\n".join(report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.data_dir / f"summary_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return report_text
    
    def _pool_data_to_df(self, pool_data: CurvePoolData) -> pd.DataFrame:
        """å°†CurvePoolDataè½¬æ¢ä¸ºDataFrame"""
        
        # åŸºæœ¬ä¿¡æ¯
        row = {
            'timestamp': pool_data.timestamp,
            'pool_address': pool_data.pool_address,
            'pool_name': pool_data.pool_name,
            'total_supply': pool_data.total_supply,
            'virtual_price': pool_data.virtual_price,
            'volume_24h': pool_data.volume_24h,
            'fees_24h': pool_data.fees_24h,
            'apy': pool_data.apy
        }
        
        # ä»£å¸ä½™é¢å’Œæ±‡ç‡
        for i, (token, balance, rate) in enumerate(zip(pool_data.tokens, pool_data.balances, pool_data.rates)):
            row[f'{token.lower()}_balance'] = balance
            row[f'{token.lower()}_rate'] = rate
        
        # è®¡ç®—é¢å¤–æŒ‡æ ‡
        if len(pool_data.balances) >= 3:  # 3Poolç­‰
            total_balance = sum(pool_data.balances)
            for i, (token, balance) in enumerate(zip(pool_data.tokens, pool_data.balances)):
                row[f'{token.lower()}_ratio'] = balance / total_balance if total_balance > 0 else 0
            
            # ä¸å¹³è¡¡åº¦è®¡ç®—
            ideal_ratio = 1.0 / len(pool_data.balances)
            deviations = [abs(balance/total_balance - ideal_ratio) for balance in pool_data.balances]
            row['max_imbalance'] = max(deviations) if deviations else 0
        
        return pd.DataFrame([row])

def demo_csv_export():
    """æ¼”ç¤ºCSVå¯¼å‡ºåŠŸèƒ½"""
    
    print("ğŸ“ Curveæ•°æ®CSVå¯¼å‡ºæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    manager = CurveDataManager()
    
    print("\n1ï¸âƒ£ è·å–å¹¶ä¿å­˜3Poolå®æ—¶æ•°æ®...")
    realtime_file = manager.save_real_time_data('3pool', save_csv=True)
    
    print("\n2ï¸âƒ£ è·å–å¹¶ä¿å­˜3Poolå†å²æ•°æ®...")
    historical_file = manager.save_historical_data('3pool', days=7, save_csv=True)
    
    print("\n3ï¸âƒ£ æ‰¹é‡ä¿å­˜æ‰€æœ‰æ± å­æ•°æ®...")
    batch_results = manager.save_all_pools_data(['3pool', 'frax'], save_csv=True)
    
    print("\n4ï¸âƒ£ åˆ—å‡ºä¿å­˜çš„æ–‡ä»¶...")
    files = manager.list_saved_files()
    for category, file_list in files.items():
        if file_list:
            print(f"ğŸ“‚ {category}: {len(file_list)} ä¸ªæ–‡ä»¶")
            for filename in file_list[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"   - {filename}")
            if len(file_list) > 3:
                print(f"   ... è¿˜æœ‰ {len(file_list) - 3} ä¸ªæ–‡ä»¶")
    
    print("\n5ï¸âƒ£ åˆ›å»ºæ±‡æ€»æŠ¥å‘Š...")
    report = manager.create_summary_report()
    print(report)
    
    print("\n6ï¸âƒ£ æµ‹è¯•æ•°æ®è¯»å–...")
    if realtime_file:
        df = manager.load_csv_data(realtime_file)
        if not df.empty:
            print(f"âœ… æˆåŠŸè¯»å–æ•°æ®: {len(df)} è¡Œ x {len(df.columns)} åˆ—")
            print("å‰å‡ åˆ—æ•°æ®:")
            print(df.head())
    
    print("\n" + "=" * 50)
    print("ğŸ‰ CSVå¯¼å‡ºæ¼”ç¤ºå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰æ•°æ®ä¿å­˜åœ¨: {manager.data_dir.absolute()}")

if __name__ == "__main__":
    demo_csv_export() 